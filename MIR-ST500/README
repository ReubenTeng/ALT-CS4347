This directory is related to the named dataset below. Files are adapted from the original project's repository.

We evaluate MusicYolo only on the "test" set since the train set was used to train the model musicyolo1.pth. For evaluation, we can comment out code and skip instructions for the train set.

To download requirements, use:
> pip install -r requirements.txt<br>
Note: Some other requirements have been excluded as they have already been downloaded when using MusicYOLO. Also note that 
Spleeter's version of tensorflow and numpy may be incompatible with other parts of the project. If errors arise, use spleeter in 
a different environment/uninstall numpy and tensorflow before installing spleeter.

To download the dataset, use:
> python get_youtube.py MIR-ST500_link.json train test

This will download 500 songs from Youtube automatically. Song id #1~#400 (training set) will be saved to "train/", #401~#500(test set) will be saved to "test/". <br>

> python do_spleeter.py train/<br>
> python do_spleeter.py test/

And then, we have to use an SVS program to extract vocal, and write the vocal file to "Vocal.wav". Here, do_spleeter.py uses Spleeter to do the job.

To get the correct format and directories for prediction and evaluation, we do the inference with the following commands:

Step1. Move the extracted vocal files into their own directory "vocal"
> python movefiles.py

Step2. Split the audio into 35 second chunks
> python splitwav.py vocal split

Step3. Onset/offset detection (use musicyolo1.pth) (From MusicYOLO directory)
```shell
python3 tools/predict.py -f exps/example/custom/yolox_singing.py -c models/musicyolo1.pth --audiodir $SPLIT_PATH --savedir $SAVE_PATH --ext .wav --device gpu
```
Step4. Merge results
> python mergeres.py vocal save merged-res

Step4. Get correct label files
> python jsontotxt.py

Step6. Evaluate
```shell
python3 tools/note_eval.py --label $MIR_ST500_TEST_LABEL_PATH --result $MERGE_PATH --offset
```

Original README:
MIR-ST500 dataset

Version: 2021.02.06

Description
MIR-ST500 dataset is a dataset created by NTU MIRLAB for the task of "automatic singing transcription".
This dataset contains 500 pop songs and the corresponding annotations of VOCAL parts.
For more information, please refer to the paper "On the Preparation and Validation of a Large-scale Dataset" (ICASSP2021).

Data Format
"MIR-ST500_link.json" contains Youtube links of these 500 songs (in dictionary structure of {id:link}). You can download corresponding audio from Youtube using these links.
"MIR-ST500_corrected.json" contains annotations of these 500 songs. It is a dictionary of {id:gt}. Here, "gt" is a list of ground truth notes (in ascending order of the onset). Each note is denoted by [onset, offset, score pitch].
"metadata.csv" contains labeler id (1~14) and verifier id (1~6) of each song in the dataset.

Each song has its own id numbering from 1 to 500. We separate these 500 songs into training set (#1 to #400) and test set (#401 to #500).
If some of the Youtube links do not work, please contact us (especially for those songs in test set !!!).

Contact us
If there is any wrong about the dataset (e.g. note label is incorrect, Youtube link does not work, etc), please contact Jyh-Shing "Roger" Jang (roger.jang@gmail.com) or Jun-You Wang (b06902046@ntu.edu.tw).
If some of the notes are incorrect, we will try our best to correct those labels and release newer version as soon as possible.